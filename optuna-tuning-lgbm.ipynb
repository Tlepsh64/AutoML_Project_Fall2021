{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing the Packages&Data","metadata":{}},{"cell_type":"code","source":"#!pip install optuna","metadata":{"execution":{"iopub.status.busy":"2022-01-12T23:34:18.790654Z","iopub.execute_input":"2022-01-12T23:34:18.791479Z","iopub.status.idle":"2022-01-12T23:34:18.795397Z","shell.execute_reply.started":"2022-01-12T23:34:18.791437Z","shell.execute_reply":"2022-01-12T23:34:18.794241Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib\nimport plotly\n\n# Models to use\nimport lightgbm as lgb\nimport catboost as cb\n\n# Importing the metrics\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\n#from sklearn.metrics import confusion_matrix\n#from sklearn.metrics import plot_confusion_matrix\n\n# For measuring the training time taken during the fit process\nimport time\n\n#from hyperopt import hp\n#from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials, space_eval\n\n# Importing the Scalers\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nimport optuna","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-12T23:34:18.809542Z","iopub.execute_input":"2022-01-12T23:34:18.809832Z","iopub.status.idle":"2022-01-12T23:34:18.818369Z","shell.execute_reply.started":"2022-01-12T23:34:18.809804Z","shell.execute_reply":"2022-01-12T23:34:18.817227Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/higgs-cleaned/higgs_cleaned.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T23:34:18.820929Z","iopub.execute_input":"2022-01-12T23:34:18.821275Z","iopub.status.idle":"2022-01-12T23:34:19.330591Z","shell.execute_reply.started":"2022-01-12T23:34:18.821230Z","shell.execute_reply":"2022-01-12T23:34:19.329691Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"X, y = df.drop('class', axis=1), df['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1864)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T23:34:19.331629Z","iopub.execute_input":"2022-01-12T23:34:19.331820Z","iopub.status.idle":"2022-01-12T23:34:19.380585Z","shell.execute_reply.started":"2022-01-12T23:34:19.331796Z","shell.execute_reply":"2022-01-12T23:34:19.379779Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# df_train, df_test = train_test_split(df, test_size=0.2, random_state=1864)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T23:34:19.381999Z","iopub.execute_input":"2022-01-12T23:34:19.382223Z","iopub.status.idle":"2022-01-12T23:34:19.387861Z","shell.execute_reply.started":"2022-01-12T23:34:19.382196Z","shell.execute_reply":"2022-01-12T23:34:19.387172Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"## Normalizing the Features into range [0-1]","metadata":{}},{"cell_type":"markdown","source":"Scaling is surely an important part of the pipeline and I will be using MinMaxScaler to this end. One can turn the feature values into the standard normal range as well but the features do not always have the gaussian shape, I've done the basic tests for checking this in the baselines notebook. ","metadata":{}},{"cell_type":"code","source":"# There is no need to scale labels since they are already in the MinMaxScaler range [0-1]\nscaler = MinMaxScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T23:34:19.389417Z","iopub.execute_input":"2022-01-12T23:34:19.390149Z","iopub.status.idle":"2022-01-12T23:34:19.420602Z","shell.execute_reply.started":"2022-01-12T23:34:19.390109Z","shell.execute_reply":"2022-01-12T23:34:19.419869Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"#converting the dataset into proper LGB format \nd_train=lgb.Dataset(X_train, label=y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T23:34:19.423860Z","iopub.execute_input":"2022-01-12T23:34:19.424086Z","iopub.status.idle":"2022-01-12T23:34:19.428102Z","shell.execute_reply.started":"2022-01-12T23:34:19.424059Z","shell.execute_reply":"2022-01-12T23:34:19.427210Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"For the meaning of search functions such as hp.uniform, you can take a look at here: http://hyperopt.github.io/hyperopt/getting-started/search_spaces/.","metadata":{}},{"cell_type":"markdown","source":"## Defining the Search Space & Objective Function","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    \n    classifier_parameters = {\n    'learning_rate':    trial.suggest_float('learning_rate', 0.2, 0.3, step=0.005),\n    'max_depth':        trial.suggest_int('max_depth', 6, 10, step=1),\n    'min_child_weight': trial.suggest_int('min_child_weight', 1, 8, step=1),\n    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.8, 1, step=0.05),\n    'subsample':        trial.suggest_uniform('subsample', 0.7, 1),\n    'num_iterations':     trial.suggest_categorical('num_iterations ', [150, 200, 350, 500]),\n    'min_child_samples':trial.suggest_int('min_child_samples', 100, 300, step = 25),\n    'num_leaves':       trial.suggest_int('num_leaves', 20, 50, step = 5),\n    'objective':        'binary',\n    'metric':           'auc',  \n    'boosting_type':    'dart',\n    'feature_pre_filter':False,\n    'random_seed':      1864\n}\n\n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n    cv_results = lgb.cv(classifier_parameters, d_train, nfold=5, verbose_eval = False, early_stopping_rounds=90, callbacks=[pruning_callback])\n    best_auc = cv_results['auc-mean'][-1]\n    #acc = cross_val_score(clf, X_train, y_train, scoring='accuracy').mean()\n    \n    return best_auc","metadata":{"execution":{"iopub.status.busy":"2022-01-12T23:34:19.429362Z","iopub.execute_input":"2022-01-12T23:34:19.429553Z","iopub.status.idle":"2022-01-12T23:34:19.443951Z","shell.execute_reply.started":"2022-01-12T23:34:19.429529Z","shell.execute_reply":"2022-01-12T23:34:19.443041Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter Tuning","metadata":{}},{"cell_type":"markdown","source":"We can now start the trials. Optuna is much easier to use compared to Hyperopt since the study object logs the important stuff regarding the trials already.","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize', study_name='Optuna_Basic_Study')\nstudy.optimize(objective, n_trials=100, show_progress_bar=True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-12T23:34:19.445992Z","iopub.execute_input":"2022-01-12T23:34:19.446286Z","iopub.status.idle":"2022-01-12T23:52:20.196193Z","shell.execute_reply.started":"2022-01-12T23:34:19.446256Z","shell.execute_reply":"2022-01-12T23:52:20.195378Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"print('Best 5-Fold CV Score on train set:', round(study.best_value, 8))","metadata":{"execution":{"iopub.status.busy":"2022-01-12T23:52:20.197829Z","iopub.execute_input":"2022-01-12T23:52:20.198382Z","iopub.status.idle":"2022-01-12T23:52:20.204863Z","shell.execute_reply.started":"2022-01-12T23:52:20.198342Z","shell.execute_reply":"2022-01-12T23:52:20.204290Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"print('Best Parameters')\nprint('-'*50)\nfor k,v in study.best_params.items():\n    print(k,':',v)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T23:52:20.205804Z","iopub.execute_input":"2022-01-12T23:52:20.206624Z","iopub.status.idle":"2022-01-12T23:52:20.222693Z","shell.execute_reply.started":"2022-01-12T23:52:20.206552Z","shell.execute_reply":"2022-01-12T23:52:20.222153Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"print('Best Trial Index:', study.best_trial.number)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T23:52:20.223906Z","iopub.execute_input":"2022-01-12T23:52:20.224122Z","iopub.status.idle":"2022-01-12T23:52:20.233446Z","shell.execute_reply.started":"2022-01-12T23:52:20.224095Z","shell.execute_reply":"2022-01-12T23:52:20.232551Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"## Plots of the Initial Hyperparameter Search","metadata":{}},{"cell_type":"code","source":"import plotly.offline as pyo\npyo.init_notebook_mode()","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:10:13.872343Z","iopub.execute_input":"2022-01-13T00:10:13.873198Z","iopub.status.idle":"2022-01-13T00:10:13.964546Z","shell.execute_reply.started":"2022-01-13T00:10:13.873149Z","shell.execute_reply":"2022-01-13T00:10:13.962991Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_param_importances(study)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:10:19.381665Z","iopub.execute_input":"2022-01-13T00:10:19.382071Z","iopub.status.idle":"2022-01-13T00:10:19.916505Z","shell.execute_reply.started":"2022-01-13T00:10:19.382038Z","shell.execute_reply":"2022-01-13T00:10:19.915717Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_param_importances(\n    study, target=lambda t: t.duration.total_seconds(), target_name=\"duration\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:10:24.781661Z","iopub.execute_input":"2022-01-13T00:10:24.782076Z","iopub.status.idle":"2022-01-13T00:10:25.390309Z","shell.execute_reply.started":"2022-01-13T00:10:24.782029Z","shell.execute_reply":"2022-01-13T00:10:25.388824Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_slice(study)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:10:28.893895Z","iopub.execute_input":"2022-01-13T00:10:28.894317Z","iopub.status.idle":"2022-01-13T00:10:29.044165Z","shell.execute_reply.started":"2022-01-13T00:10:28.894283Z","shell.execute_reply":"2022-01-13T00:10:29.043170Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:10:33.012613Z","iopub.execute_input":"2022-01-13T00:10:33.012943Z","iopub.status.idle":"2022-01-13T00:10:33.050988Z","shell.execute_reply.started":"2022-01-13T00:10:33.012912Z","shell.execute_reply":"2022-01-13T00:10:33.049815Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_parallel_coordinate(study)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:10:36.130897Z","iopub.execute_input":"2022-01-13T00:10:36.131184Z","iopub.status.idle":"2022-01-13T00:10:36.172991Z","shell.execute_reply.started":"2022-01-13T00:10:36.131154Z","shell.execute_reply":"2022-01-13T00:10:36.171914Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":"## Applying the Tuned Model on Test Data","metadata":{}},{"cell_type":"code","source":"best_params = study.best_params\n\nclf = lgb.LGBMClassifier(**best_params)\nclf.fit(X_train, y_train, verbose=False)\n\npreds = clf.predict(X_test)\n\nprint(accuracy_score(y_test, preds))","metadata":{"execution":{"iopub.status.busy":"2022-01-13T00:10:45.144638Z","iopub.execute_input":"2022-01-13T00:10:45.144909Z","iopub.status.idle":"2022-01-13T00:10:46.542186Z","shell.execute_reply.started":"2022-01-13T00:10:45.144882Z","shell.execute_reply":"2022-01-13T00:10:46.541422Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"## Saving the Model into .json/.txt","metadata":{}},{"cell_type":"code","source":"clf.booster_.save_model('model_minmax_lgbm_optuna_1.txt')","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"clf.save_model(\n    \"model3_minmax_lgbm_dart.json\",\n    format=\"json\",\n    # pool=pool  # this parameter is required only for models with categorical features.\n)\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}